### ALL DIMENSIONS ARE IN METRES

# Path to config file for robot hand geometry
# hand_geometry_filename = ../cfg/hand_geometry_rizon4s.cfg
# ==== Robot Hand Geometry Parameters ====
# ========================================
#   finger_width: the width of the finger
#   outer_diameter: the diameter of the robot hand (= maximum aperture + 2 * finger width)
#   hand_depth: the finger length (measured from hand base to finger tip)
#   hand_height: the height of the hand
#   init_bite: the minimum amount of the object to be covered by the hand
finger_width = 0.01
hand_outer_diameter = 0.12
hand_depth = 0.1736 # 0.0868
hand_height = 0.1736
init_bite = 0.01

# Path to config file for volume and image geometry
image_geometry_filename = cfg/image_geometry_15channels.cfg
# # ==== Robot Hand Geometry Parameters ====
# # ========================================
# #   volume_width: the width of the volume
# #   volume_depth: the depth of the volume
# #   volume_height: the height of the volume
# #   image_size: the size of the image (width and height; image is square)
# #   image_num_channels: the number of channels in the image
# volume_width = 0.10
# volume_depth = 0.06
# volume_height = 0.02
# image_size = 60  
# image_num_channels = 15  

# Path to directory that contains neural network parameters
weights_file = models/lenet/15channels/params/

# Preprocessing of point cloud
#   voxelize: if the cloud gets voxelized/downsampled
#   remove_outliers: if statistical outliers are removed from the cloud (used to remove noise)
#   workspace: workspace of the robot (dimensions of a cube centered at origin of point cloud)
#   camera_position: position of the camera from which the cloud was taken
#   sample_above_plane: only draws samples which do not belong to the table plane
voxelize = 0
voxel_size = 0.001
remove_outliers = 0
# Set this to the max size of a part we might have.
# TODO: Adapt for large numbers of parts.
workspace = -0.5 0.5 -0.5 0.5 -0.1 0.5
camera_position = 0 0 1
sample_above_plane = 0

# Grasp candidate generation
#   num_samples: number of samples to be drawn from the point cloud
#   num_threads: number of CPU threads to be used
#   nn_radius: neighborhood search radius for the local reference frame estimation
#   num_orientations: number of robot hand orientations to evaluate
#   num_finger_placements: number of finger placements to evaluate
#   hand_axes: axes about which the point neighborhood gets rotated (0: approach, 1: binormal, 2: axis)
#              (see https://raw.githubusercontent.com/atenpas/gpd2/master/readme/hand_frame.png)
#   deepen_hand: if the hand is pushed forward onto the object
#   friction_coeff: angle of friction cone in degrees
#   min_viable: minimum number of points required on each side to be antipodal
num_samples = 100 # Could increase this up to 2500, when we implement custom evaluation of grasps. This way we get more grasps to choose from.
num_threads = 6
nn_radius = 0.01
num_orientations = 10 # Also increase this one
num_finger_placements = 10 # And increase this one
hand_axes = 2
deepen_hand = 1
friction_coeff = 20
min_viable = 10 # This might be something to play around with.

# Filtering of candidates
#   min_aperture: the minimum gripper width
#   max_aperture: the maximum gripper width
#   workspace_grasps: dimensions of a cube centered at origin of point cloud; should be smaller than <workspace>
min_aperture = 0.0
max_aperture = 0.1
# Set this to workspace (in metres)
workspace_grasps = -0.5 0.5 -0.5 0.5 -0.1 0.5

# Filtering of candidates based on their approach direction
#   filter_approach_direction: turn filtering on/off
#   direction: direction to compare against
#   angle_thresh: angle in radians above which grasps are filtered. 
#       0.0 = only from above can grasp.
#       1.57 (pi/2) = from sides and top.
filter_approach_direction = 1
direction = 0 0 -1  
thresh_rad = 1.0

# Clustering of grasps
#   min_inliers: minimum number of inliers per cluster; set to 0 to turn off clustering
min_inliers = 0

# Grasp selection
#   num_selected: number of selected grasps (sorted by score)
# Can play with this parameter to see if we get better grasps.
num_selected = 10

# Visualization
#   plot_normals: plot the surface normals
#   plot_samples: plot the samples
#   plot_candidates: plot the grasp candidates
#   plot_filtered_candidates: plot the grasp candidates which remain after filtering
#   plot_valid_grasps: plot the candidates that are identified as valid grasps
#   plot_clustered_grasps: plot the grasps that after clustering
#   plot_selected_grasps: plot the selected grasps (final output)
# Don't visualize. I'm getting issues with docker.
plot_normals = 0
plot_samples = 0
plot_candidates = 0
plot_filtered_candidates = 0
plot_valid_grasps = 0
plot_clustered_grasps = 0
plot_selected_grasps = 0
